{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Churn_modelling(Tuning).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UtkarshGupta12/Churn_Modelling/blob/master/Churn_modelling(Tuning).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2AXJqJz0X2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbw3_rLx0jcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRsVM3CY0jhN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/UtkarshGupta12/Churn_Modelling/master/Churn_Modelling.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzOQ8P5Z0jj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzcC9S050jmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = df\n",
        "df2 = df2.drop(['RowNumber','CustomerId','Surname'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbRE6jAy0jou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[ : , 3:13].values\n",
        "y = df.iloc[ : ,13].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVqvWRjd0jrL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "bb1d667e-084f-480c-f834-779db129d2a3"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[ : , 1]=labelencoder_X_1.fit_transform(X[ : , 1])\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[ : , 2]=labelencoder_X_2.fit_transform(X[ : , 2])\n",
        "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
        "X = onehotencoder.fit_transform(X).toarray()\n",
        "X = X[ : , 1:]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SxAtzYk0jti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2 , random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaRtp-cp0jwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddimnLEU7IUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "def build_calssifier(optimizer):\n",
        "  classifier = Sequential()\n",
        "  classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
        "  classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "  classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "  classifier.compile(optimizer=optimizer,loss='binary_crossentropy',metrics = ['accuracy'])\n",
        "  return classifier\n",
        "classifier = KerasClassifier(build_fn = build_calssifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAX_qVWjXTRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parameters = {'batch_size':[25,32],\n",
        "             'nb_epoch':[100,500],\n",
        "             'optimizer':['adam','rmsprop']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnogwRjtZaB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                          param_grid = parameters,\n",
        "                          scoring = 'accuracy',\n",
        "                          cv = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaJTNRrIZtaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16987412-d76c-42af-d505-c1c9813dc50a"
      },
      "source": [
        "grid_search=grid_search.fit(X_train,y_train)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0726 13:21:08.341021 140553043347328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0726 13:21:08.359709 140553043347328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0726 13:21:08.364364 140553043347328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0726 13:21:08.415102 140553043347328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0726 13:21:08.440601 140553043347328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0726 13:21:08.449877 140553043347328 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0726 13:21:08.647931 140553043347328 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 88us/step - loss: 0.5600 - acc: 0.7960\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 86us/step - loss: 0.5616 - acc: 0.7967\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 97us/step - loss: 0.6072 - acc: 0.7936\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 109us/step - loss: 0.6560 - acc: 0.7957\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 115us/step - loss: 0.5501 - acc: 0.7931\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.5767 - acc: 0.7924\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.5612 - acc: 0.7951\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.5680 - acc: 0.7956\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 159us/step - loss: 0.5763 - acc: 0.7939\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 168us/step - loss: 0.5677 - acc: 0.7943\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 168us/step - loss: 0.5874 - acc: 0.7964\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 181us/step - loss: 0.5651 - acc: 0.7964\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 183us/step - loss: 0.5739 - acc: 0.7956\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 187us/step - loss: 0.6240 - acc: 0.7957\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 1s 198us/step - loss: 0.5808 - acc: 0.7935\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 211us/step - loss: 0.6056 - acc: 0.7931\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 218us/step - loss: 0.5688 - acc: 0.7958\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 224us/step - loss: 0.5774 - acc: 0.7960\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 225us/step - loss: 0.5593 - acc: 0.7957\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 234us/step - loss: 0.5708 - acc: 0.7961\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 251us/step - loss: 0.5581 - acc: 0.7969\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 267us/step - loss: 0.5759 - acc: 0.7954\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 278us/step - loss: 0.5444 - acc: 0.7947\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 286us/step - loss: 0.5785 - acc: 0.7957\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 301us/step - loss: 0.5588 - acc: 0.7914\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 307us/step - loss: 0.5634 - acc: 0.7935\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 315us/step - loss: 0.5782 - acc: 0.7943\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 331us/step - loss: 0.5621 - acc: 0.7960\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 335us/step - loss: 0.5609 - acc: 0.7956\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 337us/step - loss: 0.6561 - acc: 0.7943\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 2s 341us/step - loss: 0.5657 - acc: 0.7968\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 349us/step - loss: 0.5891 - acc: 0.7954\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 360us/step - loss: 0.5659 - acc: 0.7950\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 360us/step - loss: 0.5639 - acc: 0.7976\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 372us/step - loss: 0.5923 - acc: 0.7921\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 383us/step - loss: 0.5837 - acc: 0.7924\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 393us/step - loss: 0.5691 - acc: 0.7962\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 396us/step - loss: 0.5538 - acc: 0.7953\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 404us/step - loss: 0.5666 - acc: 0.7957\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 409us/step - loss: 0.5903 - acc: 0.7942\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 423us/step - loss: 0.5872 - acc: 0.7962\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 429us/step - loss: 0.6104 - acc: 0.7944\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 432us/step - loss: 0.6634 - acc: 0.7932\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 441us/step - loss: 0.5835 - acc: 0.7961\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 447us/step - loss: 0.5851 - acc: 0.7921\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 458us/step - loss: 0.5722 - acc: 0.7944\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 471us/step - loss: 0.5978 - acc: 0.7953\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 492us/step - loss: 0.6060 - acc: 0.7942\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 3s 486us/step - loss: 0.6007 - acc: 0.7944\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 502us/step - loss: 0.5925 - acc: 0.7954\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 503us/step - loss: 0.5980 - acc: 0.7961\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 508us/step - loss: 0.6074 - acc: 0.7951\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 512us/step - loss: 0.6129 - acc: 0.7946\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 530us/step - loss: 0.5949 - acc: 0.7969\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 532us/step - loss: 0.6135 - acc: 0.7936\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 536us/step - loss: 0.6116 - acc: 0.7939\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 543us/step - loss: 0.6216 - acc: 0.7960\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 543us/step - loss: 0.6104 - acc: 0.7946\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 557us/step - loss: 0.6092 - acc: 0.7944\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 566us/step - loss: 0.5966 - acc: 0.7960\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 589us/step - loss: 0.6054 - acc: 0.7956\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 596us/step - loss: 0.5996 - acc: 0.7946\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 615us/step - loss: 0.5635 - acc: 0.7956\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 614us/step - loss: 0.5822 - acc: 0.7950\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 4s 619us/step - loss: 0.5823 - acc: 0.7935\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 636us/step - loss: 0.5865 - acc: 0.7942\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 647us/step - loss: 0.5861 - acc: 0.7953\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 653us/step - loss: 0.5802 - acc: 0.7954\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 663us/step - loss: 0.5894 - acc: 0.7953\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 679us/step - loss: 0.5873 - acc: 0.7947\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 674us/step - loss: 0.6062 - acc: 0.7961\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 679us/step - loss: 0.5957 - acc: 0.7954\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 699us/step - loss: 0.6119 - acc: 0.7943\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 702us/step - loss: 0.5814 - acc: 0.7975\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 708us/step - loss: 0.6025 - acc: 0.7921\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 709us/step - loss: 0.6026 - acc: 0.7919\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 717us/step - loss: 0.6268 - acc: 0.7947\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 731us/step - loss: 0.5972 - acc: 0.7961\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 737us/step - loss: 0.6251 - acc: 0.7940\n",
            "Epoch 1/1\n",
            "7200/7200 [==============================] - 5s 740us/step - loss: 0.6612 - acc: 0.7926\n",
            "Epoch 1/1\n",
            "8000/8000 [==============================] - 6s 706us/step - loss: 0.5642 - acc: 0.7935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15aKPT0zZ8DC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_parameters =grid_search.best_params_ \n",
        "best_accuracy = grid_search.best_score_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vogavgvd4Pw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0845bce9-5e47-4261-f65b-723aa2528dfa"
      },
      "source": [
        "best_accuracy"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.796"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEB3g-P6d9JF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3c1f3dd-7ffe-4cd5-fa6c-f557e5b9c0c8"
      },
      "source": [
        "best_parameters"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 25, 'nb_epoch': 100, 'optimizer': 'adam'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    }
  ]
}